{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4441f9d0-227e-4e47-bd82-27ba2cbb65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set the seed\n",
    "np.random.seed(123456)\n",
    "random.seed(123456)\n",
    "\n",
    "\n",
    "\n",
    "# URL to the housing dataset\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data\"\n",
    "\n",
    "# Column names for the dataset\n",
    "column_names = [\n",
    "    \"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\",\n",
    "    \"dis\", \"rad\", \"tax\", \"ptratio\", \"b\", \"lstat\", \"medv\"\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "housing = pd.read_csv(url, delim_whitespace=True, names=column_names)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(housing.head())\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "# Converting `medv` to logs\n",
    "housing['log_medv'] = np.log(housing['medv'])\n",
    "\n",
    "# Converting `chas` to a categorical variable\n",
    "housing['chas'] = housing['chas'].astype('category')\n",
    "\n",
    "# Split the data into training and testing sets before transforming continuous features\n",
    "housing_train, housing_test = train_test_split(housing, test_size=0.2, random_state=123456)\n",
    "\n",
    "# Identifying continuous variables (excluding 'chas' and 'medv')\n",
    "continuous_vars = ['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "\n",
    "# 3. Apply PolynomialFeatures for 6th-degree polynomials and interactions\n",
    "poly = PolynomialFeatures(degree=6, include_bias=False, interaction_only=False)\n",
    "housing_train_poly = poly.fit_transform(housing_train[continuous_vars])\n",
    "housing_test_poly = poly.transform(housing_test[continuous_vars])\n",
    "\n",
    "# Convert the polynomial features back to DataFrame for easy handling\n",
    "poly_feature_names = poly.get_feature_names_out(continuous_vars)\n",
    "housing_train_poly_df = pd.DataFrame(housing_train_poly, columns=poly_feature_names, index=housing_train.index)\n",
    "housing_test_poly_df = pd.DataFrame(housing_test_poly, columns=poly_feature_names, index=housing_test.index)\n",
    "\n",
    "# Combine the polynomial features with the non-continuous features\n",
    "housing_train_prepped = pd.concat([housing_train_poly_df, housing_train[['chas', 'log_medv']]], axis=1)\n",
    "housing_test_prepped = pd.concat([housing_test_poly_df, housing_test[['chas', 'log_medv']]], axis=1)\n",
    "\n",
    "# Display the dimensions of the training data\n",
    "print(f\"Dimension of training data: {housing_train_prepped.shape}\")\n",
    "print(f\"Number of X variables added: {housing_train_prepped.shape[1] - len(continuous_vars) - 2}\") # Subtract original continuous variables and 'chas', 'medv'\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from math import sqrt\n",
    "\n",
    "# Extract the target variable 'log_medv' from the preprocessed training and testing sets\n",
    "y_train = housing_train_prepped['log_medv']\n",
    "y_test = housing_test_prepped['log_medv']\n",
    "\n",
    "# Select features, dropping 'log_medv' from the training and testing dataframes\n",
    "X_train = housing_train_prepped.drop(['log_medv'], axis=1)\n",
    "X_test = housing_test_prepped.drop([S'log_medv'], axis=1)\n",
    "\n",
    "# Define the preprocessing for the 'chas' column (categorical)\n",
    "preprocessor = ColumnTransformer(transformers=[('cat', OneHotEncoder(), ['chas'])], remainder='passthrough')\n",
    "\n",
    "# Create the LassoCV pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('lasso', LassoCV(cv=6, random_state=123456))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for training and test sets\n",
    "in_sample_rmse = sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "out_of_sample_rmse = sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "# Retrieve the optimal lambda (alpha) from the LassoCV model\n",
    "optimal_alpha = pipeline.named_steps['lasso'].alpha_\n",
    "\n",
    "optimal_alpha, in_sample_rmse, out_of_sample_rmse\n",
    "\n",
    "print(f\"The Optimal Alpha: {optimal_alpha}\")\n",
    "print(f\"The In Sample RMSE: {in_sample_rmse}\")\n",
    "print(f\"The OUt of Sample RMSE: {out_of_sample_rmse}\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "# Ensure numpy is imported\n",
    "ridge_alphas = np.logspace(-6, 6, 13)\n",
    "\n",
    "# Create the RidgeCV pipeline\n",
    "pipeline_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('ridge', RidgeCV(alphas=ridge_alphas, cv=6, scoring='neg_mean_squared_error'))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipeline_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_test_pred_ridge = pipeline_ridge.predict(X_test)\n",
    "\n",
    "# Calculate the out-of-sample RMSE for Ridge Regression\n",
    "out_of_sample_rmse_ridge = sqrt(mean_squared_error(y_test, y_test_pred_ridge))\n",
    "\n",
    "# Retrieve the optimal alpha (lambda) value from the RidgeCV model\n",
    "optimal_alpha_ridge = pipeline_ridge.named_steps['ridge'].alpha_\n",
    "\n",
    "optimal_alpha_ridge, out_of_sample_rmse_ridge\n",
    "print(f\"The Optimal Alpha Ridge: {optimal_alpha_ridge}\")\n",
    "print(f\"The Out of Sample RMSE Ridge: {out_of_sample_rmse_ridge}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94403124-5191-4360-900e-5cd56e16af8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
